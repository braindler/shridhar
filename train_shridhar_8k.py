#!/usr/bin/env python3
"""
–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –®—Ä–∏–¥—Ö–∞—Ä–∞ –ú–∞—Ö–∞—Ä–∞–¥–∂–∞ —Å 8K –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –Ω–∞ MacBook Pro M4
"""

import os
import json
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    TrainingArguments,
    Trainer,
    DataCollatorForLanguageModeling,
    GPT2Config,
    GPT2LMHeadModel
)
from datasets import load_from_disk
import numpy as np
from typing import Dict, List, Any
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ShridharModelConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è 8K –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    
    def __init__(self):
        self.vocab_size = 50000
        self.n_positions = 8192  # 8K –∫–æ–Ω—Ç–µ–∫—Å—Ç
        self.n_embd = 768
        self.n_layer = 12
        self.n_head = 12
        self.attn_pdrop = 0.1
        self.embd_pdrop = 0.1
        self.resid_pdrop = 0.1
        self.activation_function = "gelu_new"
        self.bos_token_id = 0
        self.eos_token_id = 1
        self.pad_token_id = 2

class ShridharTokenizer:
    """–¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞"""
    
    def __init__(self, vocab_size: int = 50000):
        self.vocab_size = vocab_size
        self.special_tokens = {
            "<|spiritual|>": 0,
            "<|dialogue|>": 1,
            "<|script|>": 2,
            "<|end|>": 3,
            "<|pad|>": 4,
            "<|unk|>": 5
        }
        self.token_to_id = {}
        self.id_to_token = {}
        self._build_vocab()
    
    def _build_vocab(self):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è"""
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
        for token, idx in self.special_tokens.items():
            self.token_to_id[token] = idx
            self.id_to_token[idx] = token
        
        # –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è BPE –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
        # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –∑–¥–µ—Å—å –±—ã–ª –±—ã –ø–æ–ª–Ω—ã–π BPE —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
        current_id = len(self.special_tokens)
        
        # –ë–∞–∑–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã
        for char in "–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è":
            if current_id < self.vocab_size:
                self.token_to_id[char] = current_id
                self.id_to_token[current_id] = char
                current_id += 1
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        for char in " .,!?;:-()[]{}":
            if current_id < self.vocab_size:
                self.token_to_id[char] = current_id
                self.id_to_token[current_id] = char
                current_id += 1
    
    def encode(self, text: str) -> List[int]:
        """–ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ —Ç–æ–∫–µ–Ω—ã"""
        tokens = []
        for char in text.lower():
            if char in self.token_to_id:
                tokens.append(self.token_to_id[char])
            else:
                tokens.append(self.special_tokens["<|unk|>"])
        return tokens
    
    def decode(self, token_ids: List[int]) -> str:
        """–î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç"""
        text = ""
        for token_id in token_ids:
            if token_id in self.id_to_token:
                text += self.id_to_token[token_id]
        return text

class ShridharDataset:
    """–î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"""
    
    def __init__(self, dataset_path: str, tokenizer: ShridharTokenizer, max_length: int = 8192):
        self.dataset = load_from_disk(dataset_path)
        self.tokenizer = tokenizer
        self.max_length = max_length
    
    def __len__(self):
        return len(self.dataset['train'])
    
    def __getitem__(self, idx):
        item = self.dataset['train'][idx]
        text = item['text']
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        if item.get('context_type') == 'spiritual_text':
            text = f"<|spiritual|>{text}<|end|>"
        elif item.get('context_type') == 'dialogue':
            text = f"<|dialogue|>{text}<|end|>"
        elif item.get('context_type') == 'script':
            text = f"<|script|>{text}<|end|>"
        
        # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º —Å –ø–æ–º–æ—â—å—é GPT-2 —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
        tokens = self.tokenizer.encode(text, add_special_tokens=True, truncation=True, max_length=self.max_length)
        
        return {
            'input_ids': torch.tensor(tokens, dtype=torch.long),
            'labels': torch.tensor(tokens, dtype=torch.long)
        }

def create_model(config: ShridharModelConfig) -> GPT2LMHeadModel:
    """–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ GPT-2 –¥–ª—è 8K –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    
    model_config = GPT2Config(
        vocab_size=config.vocab_size,
        n_positions=config.n_positions,
        n_embd=config.n_embd,
        n_layer=config.n_layer,
        n_head=config.n_head,
        attn_pdrop=config.attn_pdrop,
        embd_pdrop=config.embd_pdrop,
        resid_pdrop=config.resid_pdrop,
        activation_function=config.activation_function,
        bos_token_id=config.bos_token_id,
        eos_token_id=config.eos_token_id,
        pad_token_id=config.pad_token_id
    )
    
    model = GPT2LMHeadModel(model_config)
    return model

def setup_training_environment():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ä–µ–¥—ã –æ–±—É—á–µ–Ω–∏—è –¥–ª—è M4"""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å MPS
    if torch.backends.mps.is_available():
        device = torch.device("mps")
        logger.info("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è MPS (Metal Performance Shaders)")
    else:
        device = torch.device("cpu")
        logger.warning("‚ö†Ô∏è MPS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏
    if device.type == "mps":
        # –î–ª—è MPS –Ω–µ—Ç –ø—Ä—è–º–æ–≥–æ –∞–Ω–∞–ª–æ–≥–∞ empty_cache, –Ω–æ –º–æ–∂–Ω–æ –æ—á–∏—Å—Ç–∏—Ç—å –∫—ç—à Python
        import gc
        gc.collect()
        logger.info("üßπ –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")
    
    return device

def create_training_arguments():
    """–°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è 8K –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    
    return TrainingArguments(
        output_dir="./shridhar_8k_model",
        per_device_train_batch_size=1,        # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π batch –¥–ª—è 8K
        per_device_eval_batch_size=1,
        gradient_accumulation_steps=16,       # –ò–º–∏—Ç–∞—Ü–∏—è batch_size=16
        learning_rate=1e-4,
        num_train_epochs=3,
        max_steps=10000,
        warmup_steps=500,
        logging_steps=100,
        save_steps=500,
        eval_steps=500,
        eval_strategy="steps",
        save_strategy="steps",
        load_best_model_at_end=True,
        metric_for_best_model="eval_loss",
        greater_is_better=False,
        fp16=False,                          # MPS –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç fp16, –∏—Å–ø–æ–ª—å–∑—É–µ–º fp32
        gradient_checkpointing=True,         # –≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏
        dataloader_pin_memory=True,
        dataloader_num_workers=4,
        remove_unused_columns=False,
        report_to="tensorboard",
        run_name="shridhar_8k_training",
        save_total_limit=3,                 # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–π
        prediction_loss_only=True,
        dataloader_drop_last=True
    )

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è"""
    
    logger.info("üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –®—Ä–∏–¥—Ö–∞—Ä–∞ –ú–∞—Ö–∞—Ä–∞–¥–∂–∞ —Å 8K –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º...")
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ä–µ–¥—ã
    device = setup_training_environment()
    logger.info(f"üñ•Ô∏è –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config_path = "/Users/anton/proj/ai.nativemind.net/sridhar/combined_shridhar_alice_dataset/training_config.json"
    with open(config_path, 'r', encoding='utf-8') as f:
        training_config = json.load(f)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
    model_config = ShridharModelConfig()
    logger.info(f"üìê –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏: {model_config.n_positions} —Ç–æ–∫–µ–Ω–æ–≤, {model_config.n_layer} —Å–ª–æ–µ–≤")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ–º GPT-2 —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä)
    from transformers import GPT2Tokenizer
    tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
    tokenizer.pad_token = tokenizer.eos_token
    logger.info(f"üî§ –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä: {len(tokenizer)} —Ç–æ–∫–µ–Ω–æ–≤")
    
    # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    model_config.vocab_size = len(tokenizer)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    logger.info("üß† –°–æ–∑–¥–∞—é –º–æ–¥–µ–ª—å...")
    model = create_model(model_config)
    model.to(device)
    
    # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    logger.info(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏: {total_params:,} (–æ–±—É—á–∞–µ–º—ã—Ö: {trainable_params:,})")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
    dataset_path = "/Users/anton/proj/ai.nativemind.net/sridhar/combined_shridhar_alice_dataset"
    logger.info(f"üìö –ó–∞–≥—Ä—É–∂–∞—é –¥–∞—Ç–∞—Å–µ—Ç –∏–∑: {dataset_path}")
    
    train_dataset = ShridharDataset(dataset_path, tokenizer, max_length=model_config.n_positions)
    logger.info(f"üìñ –†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: {len(train_dataset)}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ DataCollator
    data_collator = DataCollatorForLanguageModeling(
        tokenizer=tokenizer,
        mlm=False,  # Causal LM, –Ω–µ MLM
        pad_to_multiple_of=8
    )
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è
    training_args = create_training_arguments()
    logger.info(f"‚öôÔ∏è –ê—Ä–≥—É–º–µ–Ω—Ç—ã –æ–±—É—á–µ–Ω–∏—è: batch_size={training_args.per_device_train_batch_size}, "
                f"gradient_accumulation={training_args.gradient_accumulation_steps}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
    val_dataset = ShridharDataset(dataset_path, tokenizer, max_length=model_config.n_positions)
    val_dataset.dataset = val_dataset.dataset['validation']  # –ò—Å–ø–æ–ª—å–∑—É–µ–º validation split
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–µ–Ω–µ—Ä–∞
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        data_collator=data_collator,
    )
    
    # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏
    def log_memory_usage():
        if torch.backends.mps.is_available():
            # –î–ª—è MPS –Ω–µ—Ç –ø—Ä—è–º–æ–≥–æ —Å–ø–æ—Å–æ–±–∞ –ø–æ–ª—É—á–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
            logger.info("üíæ MPS –∞–∫—Ç–∏–≤–µ–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç GPU M4")
        else:
            logger.info("üíæ CPU —Ä–µ–∂–∏–º")
    
    # –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
    logger.info("üéØ –ù–∞—á–∏–Ω–∞—é –æ–±—É—á–µ–Ω–∏–µ...")
    log_memory_usage()
    
    try:
        trainer.train()
        logger.info("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        logger.info("üíæ –°–æ—Ö—Ä–∞–Ω—è—é –º–æ–¥–µ–ª—å...")
        trainer.save_model()
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
        tokenizer_config = {
            "vocab_size": model_config.vocab_size,
            "special_tokens": tokenizer.special_tokens,
            "token_to_id": tokenizer.token_to_id,
            "id_to_token": tokenizer.id_to_token
        }
        
        with open("./shridhar_8k_model/tokenizer_config.json", 'w', encoding='utf-8') as f:
            json.dump(tokenizer_config, f, ensure_ascii=False, indent=2)
        
        logger.info("üéâ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ ./shridhar_8k_model/")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {e}")
        raise

if __name__ == "__main__":
    main()
